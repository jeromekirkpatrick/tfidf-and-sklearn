{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (TFIDF) Term Frequency - Inverse Document Frequency\n",
    "\n",
    "#### My goal is to replicate the formula that sklearn uses by default for tfidf.\n",
    "\n",
    "#### 1. Calculate term frequency.\n",
    "\n",
    "    * This is the number of times a term appears in a document. \n",
    "    * (NOT the number of times a term appears divided by the number of terms in document, which would be a normalized term frequency.)\n",
    "    \n",
    "#### 2. Calculate inverse document frequency.\n",
    "\n",
    "    * Natural log of ( (Number of documents in corpus + 1)/(Number of documents where term appears + 1) ) + 1.\n",
    "        * Notice Laplace smoothing where the numerator and denominator have 1 added is default set to True.\n",
    "        \n",
    "#### 3. Calculate term frequency - inverse document frequency (tfidf).\n",
    "\n",
    "    * Term frequency * Inverse document frequency = tfidf\n",
    "    \n",
    "#### 4. Calculate norm of tfidf.\n",
    "\n",
    "    * Euclidean norm of the vector of tfidfs.\n",
    "        * L2 (Euclidean norm) is default set to True.\n",
    "        \n",
    "#### 5. Calculate normalized tfidf of each term in document 1 (v1).\n",
    "\n",
    "    * Divide each tfidf by the tfidf norm to get the normalized tfidf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Example Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized documents of corpus = list of terms per document\n",
    "v1 = ['cat', 'hat', 'bat', 'splat', 'cat', 'bat', 'hat', 'mat', 'cat']\n",
    "v2 = ['cat', 'mat', 'cat', 'sat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents of corpus untokenized\n",
    "a = 'cat hat bat splat cat bat hat mat cat'\n",
    "b  = 'cat mat cat sat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using sklearn to calculate tfidfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize sklearn's CountVectorizer() and TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = CountVectorizer()\n",
    "TV = TfidfVectorizer()\n",
    "# TV = TfidfVectorizer(norm=None) # default set to norm='l2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CV.fit_transform([a,b])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x6 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TV.fit_transform([a,b])\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab of corpus in alphabetical order provided by CV.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat', 'cat', 'hat', 'mat', 'sat', 'splat']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term frequencies of the terms in the same order as vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert CV.fit_transform() and TV.fit_transform() compressed sparse matrix object to a list\n",
    "def matrix_to_list(matrix):\n",
    "    matrix = matrix.toarray()\n",
    "    return matrix.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 2, 1, 0, 1], [0, 2, 0, 1, 1, 0]]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_lst = matrix_to_list(count)\n",
    "count_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidfs calculated by sklearn\n",
    "Can I follow the steps of the formula to reproduce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5333344767907123,\n",
       "  0.5692078092660131,\n",
       "  0.5333344767907123,\n",
       "  0.18973593642200434,\n",
       "  0.0,\n",
       "  0.26666723839535617],\n",
       " [0.0, 0.7572644142929534, 0.0, 0.3786322071464767, 0.5321543559503558, 0.0]]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_lst = matrix_to_list(tfidf)\n",
    "tfidf_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating tfidfs from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Term Frequency for 'bat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term frequency of bat in document 1\n",
    "tf_bat_v1 = v1.count('bat')\n",
    "tf_bat_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term frequency of bat in document 2\n",
    "tf_bat_v2 = v2.count('bat')\n",
    "tf_bat_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rest of term frequency for terms in first document (v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_cat = v1.count('cat')\n",
    "tf_hat = v1.count('hat')\n",
    "tf_mat = v1.count('mat')\n",
    "tf_splat = v1.count('splat')\n",
    "tf_bat = v1.count('bat')\n",
    "tf_sat = v1.count('sat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing Term Frequency (term frequency/term count in document)\n",
    "\n",
    "NOTE: sklearn doesn't use this in its formula. I've seen multiple examples online incorporating this normalization. Not sure why to normalize at this step instead of at the end, as sklearn does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2222222222222222"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is normalizing the tf_bat_v1 value, but sklearn doesn't do this\n",
    "norm_tf_bat_v1 = v1.count('bat')/len(v1)\n",
    "norm_tf_bat_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize variable for number of documents in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_doc = len([a,b])\n",
    "num_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate number of documents where term appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_count_with_term(term,corpus):\n",
    "    count = 0\n",
    "    for doc in corpus:\n",
    "        if term in doc:\n",
    "            count += 1\n",
    "            \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of documents where the term 'bat' appears\n",
    "num_doc_with_bat = doc_count_with_term('bat', [a,b])\n",
    "num_doc_with_bat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate the inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in arguments for term and corpus\n",
    "def get_idf(term, corpus):\n",
    "    num_doc = len(corpus)\n",
    "    num_doc_with_term = doc_count_with_term(term, corpus)\n",
    "    return np.log((num_doc + 1)/(num_doc_with_term +1)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_bat = np.log((num_doc + 1)/(num_doc_with_bat +1)) + 1\n",
    "idf_cat = get_idf('cat', [a,b])\n",
    "idf_hat = get_idf('hat', [a,b])\n",
    "idf_mat = get_idf('mat', [a,b])\n",
    "idf_sat = get_idf('sat', [a,b])\n",
    "idf_splat = get_idf('splat', [a,b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bat: 1.4054651081081644\n",
      "cat: 1.0\n",
      "hat: 1.4054651081081644\n",
      "mat: 1.0\n",
      "sat: 1.4054651081081644\n",
      "splat: 1.4054651081081644\n"
     ]
    }
   ],
   "source": [
    "print(f'bat: {idf_bat}')\n",
    "print(f'cat: {idf_cat}')\n",
    "print(f'hat: {idf_hat}')\n",
    "print(f'mat: {idf_mat}')\n",
    "print(f'sat: {idf_sat}')\n",
    "print(f'splat: {idf_splat}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfidf = tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_cat = tf_cat*idf_cat\n",
    "tfidf_hat = tf_hat*idf_hat\n",
    "tfidf_mat = tf_mat*idf_mat\n",
    "tfidf_splat = tf_splat*idf_splat\n",
    "tfidf_bat = tf_bat*idf_bat\n",
    "tfidf_sat = tf_sat*idf_sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bat: 2.8109302162163288\n",
      "cat: 3.0\n",
      "hat: 2.8109302162163288\n",
      "mat: 1.0\n",
      "sat: 0.0\n",
      "splat: 1.4054651081081644\n"
     ]
    }
   ],
   "source": [
    "print(f'bat: {tfidf_bat}')\n",
    "print(f'cat: {tfidf_cat}')\n",
    "print(f'hat: {tfidf_hat}')\n",
    "print(f'mat: {tfidf_mat}')\n",
    "print(f'sat: {tfidf_sat}')\n",
    "print(f'splat: {tfidf_splat}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step back to understand how to calculate L2 Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Matrix .shape = (3,3)\n",
    "Matrix = np.array([[1,2,3],[2,3,4],[3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.74165739, 5.38516481, 7.07106781])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate L2 norms\n",
    "# one norm per row\n",
    "np.sqrt((Matrix*Matrix).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7416573867739413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.385164807134504"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify row 1\n",
    "print(np.sqrt(1**2+2**2+3**2))\n",
    "# row 2\n",
    "np.sqrt(2**2+3**2+4**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.74165739, 5.38516481, 7.07106781])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternatively using np.einsum to get squareroot of sums squared\n",
    "# get one norm per row\n",
    "norms = np.sqrt(np.einsum('ij,ij->i', Matrix, Matrix))\n",
    "norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7416573867739413"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# third way to calculate norm of first row of Matrix\n",
    "np.linalg.norm(Matrix[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26726124, 0.53452248, 0.80178373])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first row of Matrix divided by first row norm to calculate norms of elements of row\n",
    "norm_elements_row1 = Matrix[0,:]/norms[0]\n",
    "norm_elements_row1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum of squares of normed elements should equal 1\n",
    "np.sum(norm_elements_row1**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate L2 Norm for tfidfs of document 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.270482855582157"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1_tfidf_norm = np.sqrt(tfidf_cat**2 + tfidf_bat**2 + tfidf_hat**2 + tfidf_mat**2 + tfidf_splat**2)\n",
    "v1_tfidf_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use L2 Norm to calculate normalized tfidf for each term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_tfidf_bat = tf_bat*idf_bat/v1_tfidf_norm\n",
    "norm_tfidf_cat = tf_cat*idf_cat/v1_tfidf_norm\n",
    "norm_tfidf_hat = tf_hat*idf_hat/v1_tfidf_norm\n",
    "norm_tfidf_mat = tf_mat*idf_mat/v1_tfidf_norm\n",
    "norm_tfidf_sat = tf_sat*idf_sat/v1_tfidf_norm\n",
    "norm_tfidf_splat = tf_splat*idf_splat/v1_tfidf_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5333344767907123\n",
      "0.5692078092660131\n",
      "0.5333344767907123\n",
      "0.18973593642200434\n",
      "0.0\n",
      "0.26666723839535617\n"
     ]
    }
   ],
   "source": [
    "# normalized tfidfs calculated from scratch\n",
    "print(norm_tfidf_bat)\n",
    "print(norm_tfidf_cat)\n",
    "print(norm_tfidf_hat)\n",
    "print(norm_tfidf_mat)\n",
    "print(norm_tfidf_sat)\n",
    "print(norm_tfidf_splat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5333344767907123,\n",
       " 0.5692078092660131,\n",
       " 0.5333344767907123,\n",
       " 0.18973593642200434,\n",
       " 0.0,\n",
       " 0.26666723839535617]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn's tfidfs for the first document (v1)\n",
    "tfidf_lst[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test if tfidfs calculated from scratch are the same as sklearn's values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_norm_tfidfs = [norm_tfidf_bat, norm_tfidf_cat, norm_tfidf_hat, norm_tfidf_mat, norm_tfidf_sat, norm_tfidf_splat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# test if the value calculated from scratch is equal to sklearn's calculated value for tfidfs\n",
    "for scratch, sklearn in zip(scratch_norm_tfidfs, tfidf_lst[0]):\n",
    "    print(scratch==sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
